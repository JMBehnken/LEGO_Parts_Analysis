{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "file_categories = 'Categories_2.csv'\n",
    "file_parts = 'Parts_2.csv'\n",
    "file_colors = 'Colors_2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "force = False\n",
    "if force:\n",
    "    for file in [file_categories, file_parts, file_colors]:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_categories, header=None)\n",
    "df.columns = ['Cat_Num', 'Cat_Name', 'Parts']\n",
    "df = df.set_index('Cat_Num')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.bricklink.com'\n",
    "bs = BeautifulSoup(requests.get(url+'/catalogTree.asp?itemType=P&itemBrand=1000', headers=headers).text, 'lxml')\n",
    "\n",
    "cat = re.compile('catString=(\\d+)')\n",
    "\n",
    "data = []\n",
    "for link in bs.find('table', {'class':'bg-color--white catalog-list__category-list--internal catalog-tree__category-list--internal'}).findAll('a'):\n",
    "    if 'href' in link.attrs:\n",
    "        category_name = link.get_text()\n",
    "        category_number = int(re.search(cat, link['href'])[1])\n",
    "        category_elements = int(link.next_element.findNext('span').get_text()[1:-1])\n",
    "        with open(file_categories, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([category_number, category_name, category_elements])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bricklink.com/catalogList.asp?v=0&pg={}&catString={}&itemBrand=1000&catType=P&v=1&viewPrint=Y'\n",
    "num = re.compile('\\?P=(.+)')\n",
    "\n",
    "with open(file_categories, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for category_number, category_name, category_elements in tqdm(reader):\n",
    "        pages = -(-int(category_elements)//50)\n",
    "        for page in range(1, pages+1):\n",
    "            bs = BeautifulSoup(requests.get(url.format(page, category_number), headers=headers).text, 'lxml')\n",
    "\n",
    "            for tr in bs.find('table', {'class':'bg-color--white catalog-list__body-main catalog-list__body-main--alternate-row'}).findAll('tr'):\n",
    "                try:\n",
    "                    number = re.search(num, tr.find('a')['href'])[1]\n",
    "                    name = tr.find('strong').get_text()\n",
    "                    with open(file_parts, 'a') as g:\n",
    "                        writer = csv.writer(g)\n",
    "                        writer.writerow([category_number, category_name, number, name])\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_parts, header=None)\n",
    "df.columns = ['Cat_Num', 'Cat_Name', 'Part_Num', 'Part_Name']\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape(cat_num, cat_name, part_num, part_name):\n",
    "    bs = BeautifulSoup(requests.get(url.format(part_num), headers=headers).text, 'lxml')\n",
    "    td = bs.find('table', {'class':'pciColorInfoTable'}).findAll('td')\n",
    "    \n",
    "    sold_dict = {}\n",
    "    for span in td[2].findAll('span'):\n",
    "        try:\n",
    "            color = span.find('a')['href'].split('colorID=')[-1].split('&')[0]\n",
    "            sold = span.get_text().rsplit('(', 1)[-1].strip()[:-1]\n",
    "            sold_dict[color] =  sold\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for span in td[3].findAll('span'):\n",
    "        try:\n",
    "            color = span.find('a')['href'].split('colorID=')[-1].split('&')[0]\n",
    "            name = span.find('a').get_text().strip()\n",
    "            sets = span.get_text().rsplit('(', 1)[-1].strip()[:-1]\n",
    "            sold = sold_dict[color] if color in sold_dict.keys() else 0\n",
    "\n",
    "            return [cat_num, cat_name, part_num, part_name, color, name, sets, sold]\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_colors in os.listdir():\n",
    "    df_2 = pd.read_csv(file_colors, header=None)\n",
    "    df_2.columns = ['Cat_Num', 'Cat_Name', 'Part_Num', 'Part_Name', 'Color_Num', 'Color_Name', 'Num_Sets', 'Num_Sold']\n",
    "else:\n",
    "    df_2 = pd.DataFrame(columns = ['Cat_Num', 'Cat_Name', 'Part_Num', 'Part_Name', 'Color_Num', 'Color_Name', 'Num_Sets', 'Num_Sold'])\n",
    "df_2 = df_2.set_index('Part_Num')\n",
    "print(df_2.shape)\n",
    "df_2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bricklink.com/v2/catalog/catalogitem.page?P={}#T=C'\n",
    "\n",
    "from multiprocessing.dummy import Pool\n",
    "import csv\n",
    "\n",
    "pool = Pool(10)\n",
    "futures = []\n",
    "for cat_num, cat_name, part_num, part_name in tqdm(df.values):\n",
    "    if part_num not in df_2.index:\n",
    "        futures.append(pool.apply_async(scrape, [cat_num, cat_name, part_num, part_name]))\n",
    "for ans in tqdm(futures):\n",
    "    with open('Colors_2.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        data = ans.get()\n",
    "        if data:\n",
    "            writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_colors, header=None)\n",
    "df.columns = ['Cat_Num', 'Cat_Name', 'Part_Num', 'Part_Name', 'Col_Num', 'Col_Name', 'Num_Sets', 'Num_Sold']\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
